{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once to install the necessary packages\n",
    "%pip install torch\n",
    "%pip install pandas\n",
    "%pip install sklearn\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import normalize\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"books_data.csv\", nrows=40000)\n",
    "data['Title'] = data['Title'].fillna('Unknown')\n",
    "data['categories'] = data['categories'].fillna('Unknown')\n",
    "data['description'] = data['description'].fillna('')\n",
    "data['description'] = data['description'].apply(lambda x: x.lower())\n",
    "data['book_content'] = (\n",
    "    (data['Title'] + ' ') * 2\n",
    "    + data['description'] + ' '\n",
    "    + data['authors'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '') + ' '\n",
    "    + data['categories'].apply(lambda x: ' '.join(x) * 5 if isinstance(x, list) else '')\n",
    ")\n",
    "data['book_content'] = data['book_content'].str.replace(r'[^\\w\\s]', '', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embeddings = torch.load('deberta_embeddings.pt')\n",
    "print(book_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_book_embeddings = normalize(book_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_dist_matrix = cdist(normalized_book_embeddings, normalized_book_embeddings, metric='cityblock') # Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_by_manhattan(book_title, threshold, manhattan_dist_matrix):\n",
    "    idx = data[data['Title'] == book_title].index[0]\n",
    "    \n",
    "    # Compute the Manhattan distance scores\n",
    "    dist_scores = list(enumerate(manhattan_dist_matrix[idx]))\n",
    "    \n",
    "    # Sort the books based on Manhattan distance (lower distance means more similar)\n",
    "    dist_scores = sorted(dist_scores, key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    # Filter recommendations based on the threshold (optional)\n",
    "    recommendations = [(data['Title'].iloc[i], \"{:.5f}\".format(score)) \n",
    "                       for i, score in dist_scores if score <= threshold]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "folder_path = r'dumped_matrices/manhattan'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save the matrix in chunks\n",
    "chunk_size = 2048\n",
    "num_chunks = len(manhattan_dist_matrix) // chunk_size + 1\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    chunk = manhattan_dist_matrix[i * chunk_size: (i + 1) * chunk_size]\n",
    "    file_path = os.path.join(folder_path, f'manhattan_matrix_chunk_{i}.pkl')\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(chunk, f)\n",
    "    clear_output(wait=True)\n",
    "    print(f'Saved {i} / {num_chunks} chunks to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_title = ''\n",
    "while (book_title != 'q'):\n",
    "  clear_output(wait=True)\n",
    "  book_title = input(\"Enter the title of a book: \")\n",
    "  recommended_books = recommend_books_by_manhattan(book_title, 100.0, manhattan_dist_matrix)\n",
    "  f = open('manhattan_output.txt', 'w')\n",
    "  f.write('Counts: ' + str(len(recommended_books)) + '\\n\\n')\n",
    "  for book in recommended_books:\n",
    "    f.write(book[1] + ' | ' + str(book[0]) + '\\n')\n",
    "\n",
    "  print('Found: ' + str(len(recommended_books)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
