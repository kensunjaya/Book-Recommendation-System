{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e49a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"books_data.csv\", nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2371e327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'description', 'authors', 'image', 'previewLink', 'publisher',\n",
       "       'publishedDate', 'infoLink', 'categories', 'ratingsCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ce0f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Title          49999 non-null  object \n",
      " 1   description    36968 non-null  object \n",
      " 2   authors        46548 non-null  object \n",
      " 3   image          41330 non-null  object \n",
      " 4   previewLink    48665 non-null  object \n",
      " 5   publisher      35100 non-null  object \n",
      " 6   publishedDate  48247 non-null  object \n",
      " 7   infoLink       48665 non-null  object \n",
      " 8   categories     44053 non-null  object \n",
      " 9   ratingsCount   12669 non-null  float64\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd9577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'average_rating' to a numeric data type\n",
    "data['ratingsCount'] = pd.to_numeric(data['ratingsCount'], \n",
    "                                       errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b718fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'book_content' by combining 'title' and 'authors'\n",
    "data['book_content'] = (data['Title'] + ' ') * 2 + data['description'] + ' ' + data['authors'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4904a",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d28575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)  # Or any reasonable vocab size\n",
    "tokenizer.fit_on_texts(data['book_content'].values.astype('U'))\n",
    "\n",
    "# Convert the texts to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(data['book_content'].values.astype('U'))\n",
    "padded_sequences = pad_sequences(sequences, maxlen=500)  # Adjust maxlen as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0109665",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45360a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kenneth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=5000, output_dim=128, input_length=500))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))  # Extra convolutional layer\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(64, activation='relu'))  # Extra Dense layer for more complex embeddings\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000274B97BB550>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kenneth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kenneth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1503, in enumerate\n",
      "    return list(_active.values()) + list(_limbo.values())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "data['categories'] = data['categories'].fillna('Unknown')  # Ensure 'categories' column exists and has no NaNs\n",
    "labels = []\n",
    "pairs = []\n",
    "\n",
    "# Create pairs of books and assign labels\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if data['categories'].iloc[i] == data['categories'].iloc[j]:\n",
    "            labels.append(1)  # Similar books (same categories)\n",
    "        else:\n",
    "            labels.append(0)  # Dissimilar books (different categoriess)\n",
    "        pairs.append((padded_sequences[i], padded_sequences[j]))\n",
    "\n",
    "# Convert pairs and labels to numpy arrays\n",
    "import numpy as np\n",
    "labels = np.array(labels)\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "# Separate input into two arrays: one for each book in the pair\n",
    "X_train_1 = np.array([p[0] for p in pairs])\n",
    "X_train_2 = np.array([p[1] for p in pairs])\n",
    "\n",
    "cnn_model.fit(padded_sequences, labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35bb9a",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeddings = cnn_model.predict(padded_sequences)\n",
    "normalized_embeddings = normalize(embeddings)\n",
    "cosine_sim_matrix = cosine_similarity(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7711fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(book_title, threshold, cosine_sim_matrix):\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = data[data['Title'] == book_title].index[0]\n",
    "\n",
    "    # Get the cosine similarity scores for all books with this book\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [(i, \"{:.5f}\".format(score)) for i, score in sim_scores[0:] if score >= threshold]\n",
    "\n",
    "    # Get the book titles and their similarity scores\n",
    "    book_recommendations = [(data['Title'].iloc[i[0]], i[1]) for i in sim_scores]\n",
    "\n",
    "    return book_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962f40a",
   "metadata": {},
   "source": [
    "### Recommend book using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01740755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "book_title = ''\n",
    "while (book_title != 'q'):\n",
    "  clear_output(wait=True)\n",
    "  book_title = input(\"Enter the title of a book: \")\n",
    "  # recommended_books = recommend_books(book_title, threshold=0.1)\n",
    "  recommended_books = recommend_books(book_title, 0.2, cosine_sim_matrix)\n",
    "  f = open('output.txt', 'w')\n",
    "  f.write('Counts: ' + str(len(recommended_books)) + '\\n\\n')\n",
    "  for book in recommended_books:\n",
    "    f.write(book[1] + ' | ' + str(book[0]) + '\\n')\n",
    "\n",
    "  print('Found: ' + str(len(recommended_books)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
