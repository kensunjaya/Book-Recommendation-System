{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e49a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"books_data.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd9577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'average_rating' to a numeric data type\n",
    "data['ratingsCount'] = pd.to_numeric(data['ratingsCount'], \n",
    "                                       errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b718fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'book_content' by combining 'title' and 'authors'\n",
    "data['book_content'] = (data['Title'] + ' ') * 2 + data['description'] + ' ' + data['authors'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4904a",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d28575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data['book_content'].values.astype('U'))\n",
    "\n",
    "# Convert the texts to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(data['book_content'].values.astype('U'))\n",
    "padded_sequences = pad_sequences(sequences, maxlen=500)  # Adjust maxlen as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0109665",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45360a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=5000, output_dim=128, input_length=500))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))  # Extra convolutional layer\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(64, activation='relu'))  # Extra Dense layer for more complex embeddings\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "data['categories'] = data['categories'].fillna('Unknown')  # Ensure 'categories' column exists and has no NaNs\n",
    "labels = []\n",
    "pairs = []\n",
    "\n",
    "# Create pairs of books and assign labels\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if data['categories'].iloc[i] == data['categories'].iloc[j]:\n",
    "            labels.append(1)  # Similar books (same categories)\n",
    "        else:\n",
    "            labels.append(0)  # Dissimilar books (different categoriess)\n",
    "        pairs.append((padded_sequences[i], padded_sequences[j]))\n",
    "\n",
    "# Convert pairs and labels to numpy arrays\n",
    "import numpy as np\n",
    "labels = np.array(labels)\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "# Separate input into two arrays: one for each book in the pair\n",
    "X_train_1 = np.array([p[0] for p in pairs])\n",
    "X_train_2 = np.array([p[1] for p in pairs])\n",
    "\n",
    "# Define the CNN branch to be shared between both inputs\n",
    "def create_cnn_model():\n",
    "    input_layer = Input(shape=(500,))\n",
    "    embedding_layer = Embedding(input_dim=5000, output_dim=128, input_length=500)(input_layer)\n",
    "    conv_layer1 = Conv1D(filters=128, kernel_size=5, activation='relu')(embedding_layer)\n",
    "    conv_layer2 = Conv1D(filters=128, kernel_size=5, activation='relu')(conv_layer1)\n",
    "    pooling_layer = GlobalMaxPooling1D()(conv_layer2)\n",
    "    dense_layer = Dense(128, activation='relu')(pooling_layer)\n",
    "    return Model(inputs=input_layer, outputs=dense_layer)\n",
    "\n",
    "# Create two inputs for the pairs\n",
    "input_1 = Input(shape=(500,))\n",
    "input_2 = Input(shape=(500,))\n",
    "\n",
    "# Create the CNN branch and share it between both inputs\n",
    "cnn_branch = create_cnn_model()\n",
    "\n",
    "# Get the embeddings for both inputs\n",
    "output_1 = cnn_branch(input_1)\n",
    "output_2 = cnn_branch(input_2)\n",
    "\n",
    "# Concatenate the outputs and add the Dense layers\n",
    "concatenated = Concatenate()([output_1, output_2])\n",
    "dense_layer1 = Dense(128, activation='relu')(concatenated)\n",
    "dense_layer2 = Dense(64, activation='relu')(dense_layer1)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense_layer2)\n",
    "\n",
    "# Build the Siamese model\n",
    "siamese_model = Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the pairs of sequences\n",
    "with tf.device('/GPU:0'):\n",
    "    siamese_model.fit([X_train_1, X_train_2], labels, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35bb9a",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "book_embeddings = cnn_branch.predict(padded_sequences)\n",
    "normalized_book_embeddings = normalize(book_embeddings)\n",
    "cosine_sim_matrix = cosine_similarity(normalized_book_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7711fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(book_title, threshold, cosine_sim_matrix):\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = data[data['Title'] == book_title].index[0]\n",
    "\n",
    "    # Get the cosine similarity scores for all books with this book\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [(i, \"{:.5f}\".format(score)) for i, score in sim_scores[0:] if score >= threshold]\n",
    "\n",
    "    # Get the book titles and their similarity scores\n",
    "    book_recommendations = [(data['Title'].iloc[i[0]], i[1]) for i in sim_scores]\n",
    "\n",
    "    return book_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962f40a",
   "metadata": {},
   "source": [
    "### Recommend book using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01740755",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m book_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the title of a book: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# recommended_books = recommend_books(book_title, threshold=0.1)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m recommended_books \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_books\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_sim_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounts: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(recommended_books)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mrecommend_books\u001b[1;34m(book_title, threshold, cosine_sim_matrix)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend_books\u001b[39m(book_title, threshold, cosine_sim_matrix):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Get the index of the book that matches the title\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbook_title\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Get the cosine similarity scores for all books with this book\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     sim_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(cosine_sim_matrix[idx]))\n",
      "File \u001b[1;32mc:\\Users\\kenne\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5389\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5387\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5388\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[1;32m-> 5389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5392\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5393\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "book_title = ''\n",
    "while (book_title != 'q'):\n",
    "  clear_output(wait=True)\n",
    "  book_title = input(\"Enter the title of a book: \")\n",
    "  # recommended_books = recommend_books(book_title, threshold=0.1)\n",
    "  recommended_books = recommend_books(book_title, 0.2, cosine_sim_matrix)\n",
    "  f = open('output.txt', 'w')\n",
    "  f.write('Counts: ' + str(len(recommended_books)) + '\\n\\n')\n",
    "  for book in recommended_books:\n",
    "    f.write(book[1] + ' | ' + str(book[0]) + '\\n')\n",
    "\n",
    "  print('Found: ' + str(len(recommended_books)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
